{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Importing data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import lightgbm\n",
    "import catboost\n",
    "import xgboost as xg\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Shucked Weight</th>\n",
       "      <th>Viscera Weight</th>\n",
       "      <th>Shell Weight</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I</td>\n",
       "      <td>1.5250</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>28.973189</td>\n",
       "      <td>12.728926</td>\n",
       "      <td>6.647958</td>\n",
       "      <td>8.348928</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>10.418441</td>\n",
       "      <td>4.521745</td>\n",
       "      <td>2.324659</td>\n",
       "      <td>3.401940</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>1.3875</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>24.777463</td>\n",
       "      <td>11.339800</td>\n",
       "      <td>5.556502</td>\n",
       "      <td>6.662133</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>F</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>1.4125</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>50.660556</td>\n",
       "      <td>20.354941</td>\n",
       "      <td>10.991839</td>\n",
       "      <td>14.996885</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>23.289114</td>\n",
       "      <td>11.977664</td>\n",
       "      <td>4.507570</td>\n",
       "      <td>5.953395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id Sex  Length  Diameter  Height     Weight  Shucked Weight  \\\n",
       "0   0   I  1.5250    1.1750  0.3750  28.973189       12.728926   \n",
       "1   1   I  1.1000    0.8250  0.2750  10.418441        4.521745   \n",
       "2   2   M  1.3875    1.1125  0.3750  24.777463       11.339800   \n",
       "3   3   F  1.7000    1.4125  0.5000  50.660556       20.354941   \n",
       "4   4   I  1.2500    1.0125  0.3375  23.289114       11.977664   \n",
       "\n",
       "   Viscera Weight  Shell Weight  Age  \n",
       "0        6.647958      8.348928    9  \n",
       "1        2.324659      3.401940    8  \n",
       "2        5.556502      6.662133    9  \n",
       "3       10.991839     14.996885   11  \n",
       "4        4.507570      5.953395    8  "
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reducing memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique in Sex: ['I', 'M', 'F']\n"
     ]
    }
   ],
   "source": [
    "# remove unnecessary 'id' column\n",
    "train_df=train_df.drop(['id'],axis=1)\n",
    "test_df=test_df.drop(['id'],axis=1)\n",
    "\n",
    "print('Unique in Sex: {}'.format(list(train_df.Sex.unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    mem_usage_before = df.memory_usage().sum() / 1024**2\n",
    "    for i in list(df.columns):\n",
    "        if df[i].dtype == 'object':\n",
    "            df[i] = df[i].map({'I':1, 'F':2, 'M':3})\n",
    "            df[i] = df[i].astype('int8')\n",
    "        elif df[i].dtype == 'float64':\n",
    "            df[i] = df[i].astype('float32')\n",
    "        elif df[i].dtype == 'int64':\n",
    "            df[i] = df[i].astype('int8')\n",
    "        elif df[i].dtype == 'category':\n",
    "            df[i] = df[i].astype('int8')\n",
    "    \n",
    "    mem_usage_after = df.memory_usage().sum() / 1024**2\n",
    "    \n",
    "    print('Before reducing memory usage: {:.2f} Mb'.format(mem_usage_before))\n",
    "    print('After reducing memory usage: {:.2f} Mb'.format(mem_usage_after))\n",
    "    print('Difference: {:.2f} Mb that is by {:.2f}% less'.format((mem_usage_after - mem_usage_before),(100* ((mem_usage_before - mem_usage_after)/mem_usage_before))))\n",
    "    print('New df types: \\n{}'.format(df.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reducing memory usage: 5.08 Mb\n",
      "After reducing memory usage: 2.12 Mb\n",
      "Difference: -2.97 Mb that is by 58.33% less\n",
      "New df types: \n",
      "sex                  int8\n",
      "length            float32\n",
      "diameter          float32\n",
      "height            float32\n",
      "weight            float32\n",
      "shucked_weight    float32\n",
      "viscera_weight    float32\n",
      "shell_weight      float32\n",
      "age                  int8\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "reduce_memory_usage(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reducing memory usage: 3.01 Mb\n",
      "After reducing memory usage: 1.37 Mb\n",
      "Difference: -1.65 Mb that is by 54.69% less\n",
      "New df types: \n",
      "sex                  int8\n",
      "length            float32\n",
      "diameter          float32\n",
      "height            float32\n",
      "weight            float32\n",
      "shucked_weight    float32\n",
      "viscera_weight    float32\n",
      "shell_weight      float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "reduce_memory_usage(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>length</th>\n",
       "      <th>diameter</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>shucked_weight</th>\n",
       "      <th>viscera_weight</th>\n",
       "      <th>shell_weight</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.5250</td>\n",
       "      <td>1.1750</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>28.973188</td>\n",
       "      <td>12.728926</td>\n",
       "      <td>6.647958</td>\n",
       "      <td>8.348927</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1000</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>10.418441</td>\n",
       "      <td>4.521745</td>\n",
       "      <td>2.324659</td>\n",
       "      <td>3.401940</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1.3875</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>24.777464</td>\n",
       "      <td>11.339800</td>\n",
       "      <td>5.556502</td>\n",
       "      <td>6.662132</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1.7000</td>\n",
       "      <td>1.4125</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>50.660557</td>\n",
       "      <td>20.354940</td>\n",
       "      <td>10.991838</td>\n",
       "      <td>14.996885</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.2500</td>\n",
       "      <td>1.0125</td>\n",
       "      <td>0.3375</td>\n",
       "      <td>23.289114</td>\n",
       "      <td>11.977664</td>\n",
       "      <td>4.507570</td>\n",
       "      <td>5.953395</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex  length  diameter  height     weight  shucked_weight  viscera_weight  \\\n",
       "0    1  1.5250    1.1750  0.3750  28.973188       12.728926        6.647958   \n",
       "1    1  1.1000    0.8250  0.2750  10.418441        4.521745        2.324659   \n",
       "2    3  1.3875    1.1125  0.3750  24.777464       11.339800        5.556502   \n",
       "3    2  1.7000    1.4125  0.5000  50.660557       20.354940       10.991838   \n",
       "4    1  1.2500    1.0125  0.3375  23.289114       11.977664        4.507570   \n",
       "\n",
       "   shell_weight  age  \n",
       "0      8.348927    9  \n",
       "1      3.401940    8  \n",
       "2      6.662132    9  \n",
       "3     14.996885   11  \n",
       "4      5.953395    8  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = list(train_df.drop(columns = ['age']).columns)\n",
    "y = ['age']\n",
    "\n",
    "train, test = train_test_split(train_df,test_size=0.2,random_state=42, shuffle=True)\n",
    "\n",
    "def cross_val(model):\n",
    "    pred = cross_val_score(model, train[X], train[y], cv=2)\n",
    "    return pred.mean()\n",
    "\n",
    "def print_evaluate(true, predicted):  \n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mape = metrics.mean_absolute_percentage_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_square = metrics.r2_score(true, predicted)\n",
    "    print('MAE:', mae)\n",
    "    print('MAPE:', mape)\n",
    "    print('MSE:', mse)\n",
    "    print('RMSE:', rmse)\n",
    "    print('R2 Square', r2_square)\n",
    "    print('__________________________________')\n",
    "    \n",
    "def evaluate(true, predicted):\n",
    "    mae = metrics.mean_absolute_error(true, predicted)\n",
    "    mape = metrics.mean_absolute_percentage_error(true, predicted)\n",
    "    mse = metrics.mean_squared_error(true, predicted)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n",
    "    r2_score = metrics.r2_score(true, predicted)\n",
    "    return mae, mape, mse, rmse, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.3718402\n",
      "MAPE: 0.13008562226476292\n",
      "MSE: 4.2270117\n",
      "RMSE: 2.0559697\n",
      "R2 Square 0.5852441861791899\n",
      "__________________________________\n",
      "====================================\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.3034861\n",
      "MAPE: 0.12260635227791322\n",
      "MSE: 3.8026378\n",
      "RMSE: 1.9500353\n",
      "R2 Square 0.6217858149295916\n",
      "__________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>1.37184</td>\n",
       "      <td>0.130086</td>\n",
       "      <td>4.227012</td>\n",
       "      <td>2.05597</td>\n",
       "      <td>0.585244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model      MAE      MAPE       MSE     RMSE  R2_Score\n",
       "0   XGB  1.37184  0.130086  4.227012  2.05597  0.585244"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_baseline = xg.XGBRegressor(n_estimators=350 , \n",
    "                                     # disable_default_eval_metric=True,\n",
    "                            # eval_metric='mae',\n",
    "                          learning_rate=0.01 ,\n",
    "                          subsample=0.5,\n",
    "                          colsample_bytree=0.75,\n",
    "                          gamma=0.5,\n",
    "                          refresh_leaf=0,\n",
    "                          grow_policy='lossguide',\n",
    "                          max_depth=8).fit(train[X], train[y])\n",
    "\n",
    "test_pred = xgb_model_baseline.predict(test[X])\n",
    "train_pred = xgb_model_baseline.predict(train[X])\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(test[y], test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(train[y], train_pred)\n",
    "\n",
    "results_df = pd.DataFrame(data=[[\"XGB\", *evaluate(test[y], test_pred)]], \n",
    "                          columns=['Model', 'MAE', 'MAPE', 'MSE', 'RMSE', 'R2_Score'])\n",
    "\n",
    "# results_df_temp = pd.DataFrame(data=[[\"XGBoost-Baseline\", *evaluate(test[y], test_pred)]], \n",
    "#                             columns=['Model', 'MAE', 'MAPE', 'MSE', 'RMSE', 'R2_Score'])\n",
    "# results_df = results_df.append(results_df_temp, ignore_index=True)\n",
    "\n",
    "# 1.37184\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714842449331268"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val(xgb_model_baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.354312797248433\n",
      "MAPE: 0.12763432663184454\n",
      "MSE: 4.285927766757646\n",
      "RMSE: 2.07024823795545\n",
      "R2 Square 0.5794633129041176\n",
      "__________________________________\n",
      "====================================\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.2199786162111796\n",
      "MAPE: 0.11421837384534882\n",
      "MSE: 3.786010012702472\n",
      "RMSE: 1.9457672041388898\n",
      "R2 Square 0.6234396293682823\n",
      "__________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>1.371840</td>\n",
       "      <td>0.130086</td>\n",
       "      <td>4.227012</td>\n",
       "      <td>2.055970</td>\n",
       "      <td>0.585244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.354313</td>\n",
       "      <td>0.127634</td>\n",
       "      <td>4.285928</td>\n",
       "      <td>2.070248</td>\n",
       "      <td>0.579463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       MAE      MAPE       MSE      RMSE  R2_Score\n",
       "0       XGB  1.371840  0.130086  4.227012  2.055970  0.585244\n",
       "1  LightGBM  1.354313  0.127634  4.285928  2.070248  0.579463"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_gbm_model = lightgbm.LGBMRegressor(\n",
    "    objective='regression_l1',\n",
    "    device_type='cpu',\n",
    "    metrics='mae',\n",
    "    n_estimators=1200 , \n",
    "    learning_rate=0.03 ,\n",
    "    num_leaves=64,\n",
    "    colsample_bytree=0.75,\n",
    "    min_split_gain=0.3,\n",
    "    max_depth=10).fit(train[X], train[y])\n",
    "\n",
    "\n",
    "test_pred = light_gbm_model.predict(test[X])\n",
    "train_pred = light_gbm_model.predict(train[X])\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(test[y], test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(train[y], train_pred)\n",
    "\n",
    "results_df_temp = pd.DataFrame(data=[[\"LightGBM\", *evaluate(test[y], test_pred)]], \n",
    "                            columns=['Model', 'MAE', 'MAPE', 'MSE', 'RMSE', 'R2_Score'])\n",
    "results_df = results_df.append(results_df_temp, ignore_index=True)\n",
    "\n",
    "# 1.3543\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подобрать сабсемпл еще лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accuracy',\n",
       " 'adjusted_mutual_info_score',\n",
       " 'adjusted_rand_score',\n",
       " 'average_precision',\n",
       " 'balanced_accuracy',\n",
       " 'completeness_score',\n",
       " 'explained_variance',\n",
       " 'f1',\n",
       " 'f1_macro',\n",
       " 'f1_micro',\n",
       " 'f1_samples',\n",
       " 'f1_weighted',\n",
       " 'fowlkes_mallows_score',\n",
       " 'homogeneity_score',\n",
       " 'jaccard',\n",
       " 'jaccard_macro',\n",
       " 'jaccard_micro',\n",
       " 'jaccard_samples',\n",
       " 'jaccard_weighted',\n",
       " 'matthews_corrcoef',\n",
       " 'max_error',\n",
       " 'mutual_info_score',\n",
       " 'neg_brier_score',\n",
       " 'neg_log_loss',\n",
       " 'neg_mean_absolute_error',\n",
       " 'neg_mean_absolute_percentage_error',\n",
       " 'neg_mean_gamma_deviance',\n",
       " 'neg_mean_poisson_deviance',\n",
       " 'neg_mean_squared_error',\n",
       " 'neg_mean_squared_log_error',\n",
       " 'neg_median_absolute_error',\n",
       " 'neg_negative_likelihood_ratio',\n",
       " 'neg_root_mean_squared_error',\n",
       " 'normalized_mutual_info_score',\n",
       " 'positive_likelihood_ratio',\n",
       " 'precision',\n",
       " 'precision_macro',\n",
       " 'precision_micro',\n",
       " 'precision_samples',\n",
       " 'precision_weighted',\n",
       " 'r2',\n",
       " 'rand_score',\n",
       " 'recall',\n",
       " 'recall_macro',\n",
       " 'recall_micro',\n",
       " 'recall_samples',\n",
       " 'recall_weighted',\n",
       " 'roc_auc',\n",
       " 'roc_auc_ovo',\n",
       " 'roc_auc_ovo_weighted',\n",
       " 'roc_auc_ovr',\n",
       " 'roc_auc_ovr_weighted',\n",
       " 'top_k_accuracy',\n",
       " 'v_measure_score']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.get_scorer_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 72 candidates, totalling 144 fits\n",
      "[CV 1/2; 1/72] START learning_rate=0.01, max_depth=5, n_estimators=300..........\n",
      "[CV 1/2; 1/72] END learning_rate=0.01, max_depth=5, n_estimators=300;, score=-1.382 total time=   2.4s\n",
      "[CV 2/2; 1/72] START learning_rate=0.01, max_depth=5, n_estimators=300..........\n",
      "[CV 2/2; 1/72] END learning_rate=0.01, max_depth=5, n_estimators=300;, score=-1.400 total time=   2.4s\n",
      "[CV 1/2; 2/72] START learning_rate=0.01, max_depth=5, n_estimators=400..........\n",
      "[CV 1/2; 2/72] END learning_rate=0.01, max_depth=5, n_estimators=400;, score=-1.385 total time=   3.1s\n",
      "[CV 2/2; 2/72] START learning_rate=0.01, max_depth=5, n_estimators=400..........\n",
      "[CV 2/2; 2/72] END learning_rate=0.01, max_depth=5, n_estimators=400;, score=-1.400 total time=   3.2s\n",
      "[CV 1/2; 3/72] START learning_rate=0.01, max_depth=5, n_estimators=500..........\n",
      "[CV 1/2; 3/72] END learning_rate=0.01, max_depth=5, n_estimators=500;, score=-1.396 total time=   4.0s\n",
      "[CV 2/2; 3/72] START learning_rate=0.01, max_depth=5, n_estimators=500..........\n",
      "[CV 2/2; 3/72] END learning_rate=0.01, max_depth=5, n_estimators=500;, score=-1.409 total time=   3.8s\n",
      "[CV 1/2; 4/72] START learning_rate=0.01, max_depth=5, n_estimators=600..........\n",
      "[CV 1/2; 4/72] END learning_rate=0.01, max_depth=5, n_estimators=600;, score=-1.401 total time=   4.8s\n",
      "[CV 2/2; 4/72] START learning_rate=0.01, max_depth=5, n_estimators=600..........\n",
      "[CV 2/2; 4/72] END learning_rate=0.01, max_depth=5, n_estimators=600;, score=-1.414 total time=   4.7s\n",
      "[CV 1/2; 5/72] START learning_rate=0.01, max_depth=6, n_estimators=300..........\n",
      "[CV 1/2; 5/72] END learning_rate=0.01, max_depth=6, n_estimators=300;, score=-1.376 total time=   3.1s\n",
      "[CV 2/2; 5/72] START learning_rate=0.01, max_depth=6, n_estimators=300..........\n",
      "[CV 2/2; 5/72] END learning_rate=0.01, max_depth=6, n_estimators=300;, score=-1.395 total time=   3.1s\n",
      "[CV 1/2; 6/72] START learning_rate=0.01, max_depth=6, n_estimators=400..........\n",
      "[CV 1/2; 6/72] END learning_rate=0.01, max_depth=6, n_estimators=400;, score=-1.380 total time=   4.1s\n",
      "[CV 2/2; 6/72] START learning_rate=0.01, max_depth=6, n_estimators=400..........\n",
      "[CV 2/2; 6/72] END learning_rate=0.01, max_depth=6, n_estimators=400;, score=-1.394 total time=   4.0s\n",
      "[CV 1/2; 7/72] START learning_rate=0.01, max_depth=6, n_estimators=500..........\n",
      "[CV 1/2; 7/72] END learning_rate=0.01, max_depth=6, n_estimators=500;, score=-1.393 total time=   5.0s\n",
      "[CV 2/2; 7/72] START learning_rate=0.01, max_depth=6, n_estimators=500..........\n",
      "[CV 2/2; 7/72] END learning_rate=0.01, max_depth=6, n_estimators=500;, score=-1.404 total time=   5.0s\n",
      "[CV 1/2; 8/72] START learning_rate=0.01, max_depth=6, n_estimators=600..........\n",
      "[CV 1/2; 8/72] END learning_rate=0.01, max_depth=6, n_estimators=600;, score=-1.399 total time=   5.9s\n",
      "[CV 2/2; 8/72] START learning_rate=0.01, max_depth=6, n_estimators=600..........\n",
      "[CV 2/2; 8/72] END learning_rate=0.01, max_depth=6, n_estimators=600;, score=-1.410 total time=   5.8s\n",
      "[CV 1/2; 9/72] START learning_rate=0.01, max_depth=7, n_estimators=300..........\n",
      "[CV 1/2; 9/72] END learning_rate=0.01, max_depth=7, n_estimators=300;, score=-1.378 total time=   3.3s\n",
      "[CV 2/2; 9/72] START learning_rate=0.01, max_depth=7, n_estimators=300..........\n",
      "[CV 2/2; 9/72] END learning_rate=0.01, max_depth=7, n_estimators=300;, score=-1.395 total time=   3.2s\n",
      "[CV 1/2; 10/72] START learning_rate=0.01, max_depth=7, n_estimators=400.........\n",
      "[CV 1/2; 10/72] END learning_rate=0.01, max_depth=7, n_estimators=400;, score=-1.383 total time=   4.7s\n",
      "[CV 2/2; 10/72] START learning_rate=0.01, max_depth=7, n_estimators=400.........\n",
      "[CV 2/2; 10/72] END learning_rate=0.01, max_depth=7, n_estimators=400;, score=-1.392 total time=   4.8s\n",
      "[CV 1/2; 11/72] START learning_rate=0.01, max_depth=7, n_estimators=500.........\n",
      "[CV 1/2; 11/72] END learning_rate=0.01, max_depth=7, n_estimators=500;, score=-1.397 total time=   5.8s\n",
      "[CV 2/2; 11/72] START learning_rate=0.01, max_depth=7, n_estimators=500.........\n",
      "[CV 2/2; 11/72] END learning_rate=0.01, max_depth=7, n_estimators=500;, score=-1.403 total time=   6.3s\n",
      "[CV 1/2; 12/72] START learning_rate=0.01, max_depth=7, n_estimators=600.........\n",
      "[CV 1/2; 12/72] END learning_rate=0.01, max_depth=7, n_estimators=600;, score=-1.403 total time=   7.1s\n",
      "[CV 2/2; 12/72] START learning_rate=0.01, max_depth=7, n_estimators=600.........\n",
      "[CV 2/2; 12/72] END learning_rate=0.01, max_depth=7, n_estimators=600;, score=-1.410 total time=   6.4s\n",
      "[CV 1/2; 13/72] START learning_rate=0.01, max_depth=8, n_estimators=300.........\n",
      "[CV 1/2; 13/72] END learning_rate=0.01, max_depth=8, n_estimators=300;, score=-1.382 total time=   4.4s\n",
      "[CV 2/2; 13/72] START learning_rate=0.01, max_depth=8, n_estimators=300.........\n",
      "[CV 2/2; 13/72] END learning_rate=0.01, max_depth=8, n_estimators=300;, score=-1.399 total time=   4.6s\n",
      "[CV 1/2; 14/72] START learning_rate=0.01, max_depth=8, n_estimators=400.........\n",
      "[CV 1/2; 14/72] END learning_rate=0.01, max_depth=8, n_estimators=400;, score=-1.387 total time=   6.2s\n",
      "[CV 2/2; 14/72] START learning_rate=0.01, max_depth=8, n_estimators=400.........\n",
      "[CV 2/2; 14/72] END learning_rate=0.01, max_depth=8, n_estimators=400;, score=-1.396 total time=   6.2s\n",
      "[CV 1/2; 15/72] START learning_rate=0.01, max_depth=8, n_estimators=500.........\n",
      "[CV 1/2; 15/72] END learning_rate=0.01, max_depth=8, n_estimators=500;, score=-1.401 total time=   7.4s\n",
      "[CV 2/2; 15/72] START learning_rate=0.01, max_depth=8, n_estimators=500.........\n",
      "[CV 2/2; 15/72] END learning_rate=0.01, max_depth=8, n_estimators=500;, score=-1.408 total time=   6.7s\n",
      "[CV 1/2; 16/72] START learning_rate=0.01, max_depth=8, n_estimators=600.........\n",
      "[CV 1/2; 16/72] END learning_rate=0.01, max_depth=8, n_estimators=600;, score=-1.407 total time=   8.6s\n",
      "[CV 2/2; 16/72] START learning_rate=0.01, max_depth=8, n_estimators=600.........\n",
      "[CV 2/2; 16/72] END learning_rate=0.01, max_depth=8, n_estimators=600;, score=-1.414 total time=   8.9s\n",
      "[CV 1/2; 17/72] START learning_rate=0.01, max_depth=9, n_estimators=300.........\n",
      "[CV 1/2; 17/72] END learning_rate=0.01, max_depth=9, n_estimators=300;, score=-1.387 total time=   5.4s\n",
      "[CV 2/2; 17/72] START learning_rate=0.01, max_depth=9, n_estimators=300.........\n",
      "[CV 2/2; 17/72] END learning_rate=0.01, max_depth=9, n_estimators=300;, score=-1.404 total time=   5.5s\n",
      "[CV 1/2; 18/72] START learning_rate=0.01, max_depth=9, n_estimators=400.........\n",
      "[CV 1/2; 18/72] END learning_rate=0.01, max_depth=9, n_estimators=400;, score=-1.391 total time=   7.2s\n",
      "[CV 2/2; 18/72] START learning_rate=0.01, max_depth=9, n_estimators=400.........\n",
      "[CV 2/2; 18/72] END learning_rate=0.01, max_depth=9, n_estimators=400;, score=-1.401 total time=   7.3s\n",
      "[CV 1/2; 19/72] START learning_rate=0.01, max_depth=9, n_estimators=500.........\n",
      "[CV 1/2; 19/72] END learning_rate=0.01, max_depth=9, n_estimators=500;, score=-1.405 total time=   8.5s\n",
      "[CV 2/2; 19/72] START learning_rate=0.01, max_depth=9, n_estimators=500.........\n",
      "[CV 2/2; 19/72] END learning_rate=0.01, max_depth=9, n_estimators=500;, score=-1.413 total time=   7.6s\n",
      "[CV 1/2; 20/72] START learning_rate=0.01, max_depth=9, n_estimators=600.........\n",
      "[CV 1/2; 20/72] END learning_rate=0.01, max_depth=9, n_estimators=600;, score=-1.412 total time=   9.8s\n",
      "[CV 2/2; 20/72] START learning_rate=0.01, max_depth=9, n_estimators=600.........\n",
      "[CV 2/2; 20/72] END learning_rate=0.01, max_depth=9, n_estimators=600;, score=-1.420 total time=  10.7s\n",
      "[CV 1/2; 21/72] START learning_rate=0.01, max_depth=10, n_estimators=300........\n",
      "[CV 1/2; 21/72] END learning_rate=0.01, max_depth=10, n_estimators=300;, score=-1.395 total time=   6.1s\n",
      "[CV 2/2; 21/72] START learning_rate=0.01, max_depth=10, n_estimators=300........\n",
      "[CV 2/2; 21/72] END learning_rate=0.01, max_depth=10, n_estimators=300;, score=-1.409 total time=   6.1s\n",
      "[CV 1/2; 22/72] START learning_rate=0.01, max_depth=10, n_estimators=400........\n",
      "[CV 1/2; 22/72] END learning_rate=0.01, max_depth=10, n_estimators=400;, score=-1.399 total time=   8.3s\n",
      "[CV 2/2; 22/72] START learning_rate=0.01, max_depth=10, n_estimators=400........\n",
      "[CV 2/2; 22/72] END learning_rate=0.01, max_depth=10, n_estimators=400;, score=-1.404 total time=   8.3s\n",
      "[CV 1/2; 23/72] START learning_rate=0.01, max_depth=10, n_estimators=500........\n",
      "[CV 1/2; 23/72] END learning_rate=0.01, max_depth=10, n_estimators=500;, score=-1.413 total time=  10.0s\n",
      "[CV 2/2; 23/72] START learning_rate=0.01, max_depth=10, n_estimators=500........\n",
      "[CV 2/2; 23/72] END learning_rate=0.01, max_depth=10, n_estimators=500;, score=-1.417 total time=  10.4s\n",
      "[CV 1/2; 24/72] START learning_rate=0.01, max_depth=10, n_estimators=600........\n",
      "[CV 1/2; 24/72] END learning_rate=0.01, max_depth=10, n_estimators=600;, score=-1.421 total time=  12.1s\n",
      "[CV 2/2; 24/72] START learning_rate=0.01, max_depth=10, n_estimators=600........\n",
      "[CV 2/2; 24/72] END learning_rate=0.01, max_depth=10, n_estimators=600;, score=-1.424 total time=  11.6s\n",
      "[CV 1/2; 25/72] START learning_rate=0.02, max_depth=5, n_estimators=300.........\n",
      "[CV 1/2; 25/72] END learning_rate=0.02, max_depth=5, n_estimators=300;, score=-1.401 total time=   2.4s\n",
      "[CV 2/2; 25/72] START learning_rate=0.02, max_depth=5, n_estimators=300.........\n",
      "[CV 2/2; 25/72] END learning_rate=0.02, max_depth=5, n_estimators=300;, score=-1.414 total time=   2.2s\n",
      "[CV 1/2; 26/72] START learning_rate=0.02, max_depth=5, n_estimators=400.........\n",
      "[CV 1/2; 26/72] END learning_rate=0.02, max_depth=5, n_estimators=400;, score=-1.404 total time=   3.0s\n",
      "[CV 2/2; 26/72] START learning_rate=0.02, max_depth=5, n_estimators=400.........\n",
      "[CV 2/2; 26/72] END learning_rate=0.02, max_depth=5, n_estimators=400;, score=-1.416 total time=   3.0s\n",
      "[CV 1/2; 27/72] START learning_rate=0.02, max_depth=5, n_estimators=500.........\n",
      "[CV 1/2; 27/72] END learning_rate=0.02, max_depth=5, n_estimators=500;, score=-1.404 total time=   3.7s\n",
      "[CV 2/2; 27/72] START learning_rate=0.02, max_depth=5, n_estimators=500.........\n",
      "[CV 2/2; 27/72] END learning_rate=0.02, max_depth=5, n_estimators=500;, score=-1.415 total time=   3.8s\n",
      "[CV 1/2; 28/72] START learning_rate=0.02, max_depth=5, n_estimators=600.........\n",
      "[CV 1/2; 28/72] END learning_rate=0.02, max_depth=5, n_estimators=600;, score=-1.404 total time=   4.5s\n",
      "[CV 2/2; 28/72] START learning_rate=0.02, max_depth=5, n_estimators=600.........\n",
      "[CV 2/2; 28/72] END learning_rate=0.02, max_depth=5, n_estimators=600;, score=-1.415 total time=   4.5s\n",
      "[CV 1/2; 29/72] START learning_rate=0.02, max_depth=6, n_estimators=300.........\n",
      "[CV 1/2; 29/72] END learning_rate=0.02, max_depth=6, n_estimators=300;, score=-1.400 total time=   2.9s\n",
      "[CV 2/2; 29/72] START learning_rate=0.02, max_depth=6, n_estimators=300.........\n",
      "[CV 2/2; 29/72] END learning_rate=0.02, max_depth=6, n_estimators=300;, score=-1.410 total time=   2.9s\n",
      "[CV 1/2; 30/72] START learning_rate=0.02, max_depth=6, n_estimators=400.........\n",
      "[CV 1/2; 30/72] END learning_rate=0.02, max_depth=6, n_estimators=400;, score=-1.403 total time=   4.0s\n",
      "[CV 2/2; 30/72] START learning_rate=0.02, max_depth=6, n_estimators=400.........\n",
      "[CV 2/2; 30/72] END learning_rate=0.02, max_depth=6, n_estimators=400;, score=-1.412 total time=   4.1s\n",
      "[CV 1/2; 31/72] START learning_rate=0.02, max_depth=6, n_estimators=500.........\n",
      "[CV 1/2; 31/72] END learning_rate=0.02, max_depth=6, n_estimators=500;, score=-1.405 total time=   4.7s\n",
      "[CV 2/2; 31/72] START learning_rate=0.02, max_depth=6, n_estimators=500.........\n",
      "[CV 2/2; 31/72] END learning_rate=0.02, max_depth=6, n_estimators=500;, score=-1.412 total time=   4.7s\n",
      "[CV 1/2; 32/72] START learning_rate=0.02, max_depth=6, n_estimators=600.........\n",
      "[CV 1/2; 32/72] END learning_rate=0.02, max_depth=6, n_estimators=600;, score=-1.406 total time=   5.7s\n",
      "[CV 2/2; 32/72] START learning_rate=0.02, max_depth=6, n_estimators=600.........\n",
      "[CV 2/2; 32/72] END learning_rate=0.02, max_depth=6, n_estimators=600;, score=-1.413 total time=   5.8s\n",
      "[CV 1/2; 33/72] START learning_rate=0.02, max_depth=7, n_estimators=300.........\n",
      "[CV 1/2; 33/72] END learning_rate=0.02, max_depth=7, n_estimators=300;, score=-1.403 total time=   3.6s\n",
      "[CV 2/2; 33/72] START learning_rate=0.02, max_depth=7, n_estimators=300.........\n",
      "[CV 2/2; 33/72] END learning_rate=0.02, max_depth=7, n_estimators=300;, score=-1.410 total time=   3.6s\n",
      "[CV 1/2; 34/72] START learning_rate=0.02, max_depth=7, n_estimators=400.........\n",
      "[CV 1/2; 34/72] END learning_rate=0.02, max_depth=7, n_estimators=400;, score=-1.408 total time=   4.7s\n",
      "[CV 2/2; 34/72] START learning_rate=0.02, max_depth=7, n_estimators=400.........\n",
      "[CV 2/2; 34/72] END learning_rate=0.02, max_depth=7, n_estimators=400;, score=-1.414 total time=   4.9s\n",
      "[CV 1/2; 35/72] START learning_rate=0.02, max_depth=7, n_estimators=500.........\n",
      "[CV 1/2; 35/72] END learning_rate=0.02, max_depth=7, n_estimators=500;, score=-1.410 total time=   6.1s\n",
      "[CV 2/2; 35/72] START learning_rate=0.02, max_depth=7, n_estimators=500.........\n",
      "[CV 2/2; 35/72] END learning_rate=0.02, max_depth=7, n_estimators=500;, score=-1.416 total time=   5.9s\n",
      "[CV 1/2; 36/72] START learning_rate=0.02, max_depth=7, n_estimators=600.........\n",
      "[CV 1/2; 36/72] END learning_rate=0.02, max_depth=7, n_estimators=600;, score=-1.412 total time=   6.9s\n",
      "[CV 2/2; 36/72] START learning_rate=0.02, max_depth=7, n_estimators=600.........\n",
      "[CV 2/2; 36/72] END learning_rate=0.02, max_depth=7, n_estimators=600;, score=-1.417 total time=   6.9s\n",
      "[CV 1/2; 37/72] START learning_rate=0.02, max_depth=8, n_estimators=300.........\n",
      "[CV 1/2; 37/72] END learning_rate=0.02, max_depth=8, n_estimators=300;, score=-1.407 total time=   4.4s\n",
      "[CV 2/2; 37/72] START learning_rate=0.02, max_depth=8, n_estimators=300.........\n",
      "[CV 2/2; 37/72] END learning_rate=0.02, max_depth=8, n_estimators=300;, score=-1.414 total time=   4.4s\n",
      "[CV 1/2; 38/72] START learning_rate=0.02, max_depth=8, n_estimators=400.........\n",
      "[CV 1/2; 38/72] END learning_rate=0.02, max_depth=8, n_estimators=400;, score=-1.413 total time=   5.6s\n",
      "[CV 2/2; 38/72] START learning_rate=0.02, max_depth=8, n_estimators=400.........\n",
      "[CV 2/2; 38/72] END learning_rate=0.02, max_depth=8, n_estimators=400;, score=-1.420 total time=   5.7s\n",
      "[CV 1/2; 39/72] START learning_rate=0.02, max_depth=8, n_estimators=500.........\n",
      "[CV 1/2; 39/72] END learning_rate=0.02, max_depth=8, n_estimators=500;, score=-1.416 total time=   7.2s\n",
      "[CV 2/2; 39/72] START learning_rate=0.02, max_depth=8, n_estimators=500.........\n",
      "[CV 2/2; 39/72] END learning_rate=0.02, max_depth=8, n_estimators=500;, score=-1.422 total time=   6.8s\n",
      "[CV 1/2; 40/72] START learning_rate=0.02, max_depth=8, n_estimators=600.........\n",
      "[CV 1/2; 40/72] END learning_rate=0.02, max_depth=8, n_estimators=600;, score=-1.418 total time=   8.3s\n",
      "[CV 2/2; 40/72] START learning_rate=0.02, max_depth=8, n_estimators=600.........\n",
      "[CV 2/2; 40/72] END learning_rate=0.02, max_depth=8, n_estimators=600;, score=-1.424 total time=   9.7s\n",
      "[CV 1/2; 41/72] START learning_rate=0.02, max_depth=9, n_estimators=300.........\n",
      "[CV 1/2; 41/72] END learning_rate=0.02, max_depth=9, n_estimators=300;, score=-1.413 total time=   6.0s\n",
      "[CV 2/2; 41/72] START learning_rate=0.02, max_depth=9, n_estimators=300.........\n",
      "[CV 2/2; 41/72] END learning_rate=0.02, max_depth=9, n_estimators=300;, score=-1.420 total time=   5.8s\n",
      "[CV 1/2; 42/72] START learning_rate=0.02, max_depth=9, n_estimators=400.........\n",
      "[CV 1/2; 42/72] END learning_rate=0.02, max_depth=9, n_estimators=400;, score=-1.418 total time=   7.2s\n",
      "[CV 2/2; 42/72] START learning_rate=0.02, max_depth=9, n_estimators=400.........\n",
      "[CV 2/2; 42/72] END learning_rate=0.02, max_depth=9, n_estimators=400;, score=-1.427 total time=   7.7s\n",
      "[CV 1/2; 43/72] START learning_rate=0.02, max_depth=9, n_estimators=500.........\n",
      "[CV 1/2; 43/72] END learning_rate=0.02, max_depth=9, n_estimators=500;, score=-1.422 total time=   9.3s\n",
      "[CV 2/2; 43/72] START learning_rate=0.02, max_depth=9, n_estimators=500.........\n",
      "[CV 2/2; 43/72] END learning_rate=0.02, max_depth=9, n_estimators=500;, score=-1.430 total time=   8.9s\n",
      "[CV 1/2; 44/72] START learning_rate=0.02, max_depth=9, n_estimators=600.........\n",
      "[CV 1/2; 44/72] END learning_rate=0.02, max_depth=9, n_estimators=600;, score=-1.426 total time=  10.4s\n",
      "[CV 2/2; 44/72] START learning_rate=0.02, max_depth=9, n_estimators=600.........\n",
      "[CV 2/2; 44/72] END learning_rate=0.02, max_depth=9, n_estimators=600;, score=-1.433 total time=  10.1s\n",
      "[CV 1/2; 45/72] START learning_rate=0.02, max_depth=10, n_estimators=300........\n",
      "[CV 1/2; 45/72] END learning_rate=0.02, max_depth=10, n_estimators=300;, score=-1.422 total time=   6.3s\n",
      "[CV 2/2; 45/72] START learning_rate=0.02, max_depth=10, n_estimators=300........\n",
      "[CV 2/2; 45/72] END learning_rate=0.02, max_depth=10, n_estimators=300;, score=-1.426 total time=   6.3s\n",
      "[CV 1/2; 46/72] START learning_rate=0.02, max_depth=10, n_estimators=400........\n",
      "[CV 1/2; 46/72] END learning_rate=0.02, max_depth=10, n_estimators=400;, score=-1.428 total time=   7.5s\n",
      "[CV 2/2; 46/72] START learning_rate=0.02, max_depth=10, n_estimators=400........\n",
      "[CV 2/2; 46/72] END learning_rate=0.02, max_depth=10, n_estimators=400;, score=-1.431 total time=   7.5s\n",
      "[CV 1/2; 47/72] START learning_rate=0.02, max_depth=10, n_estimators=500........\n",
      "[CV 1/2; 47/72] END learning_rate=0.02, max_depth=10, n_estimators=500;, score=-1.434 total time=   9.4s\n",
      "[CV 2/2; 47/72] START learning_rate=0.02, max_depth=10, n_estimators=500........\n",
      "[CV 2/2; 47/72] END learning_rate=0.02, max_depth=10, n_estimators=500;, score=-1.435 total time=   9.6s\n",
      "[CV 1/2; 48/72] START learning_rate=0.02, max_depth=10, n_estimators=600........\n",
      "[CV 1/2; 48/72] END learning_rate=0.02, max_depth=10, n_estimators=600;, score=-1.439 total time=  11.2s\n",
      "[CV 2/2; 48/72] START learning_rate=0.02, max_depth=10, n_estimators=600........\n",
      "[CV 2/2; 48/72] END learning_rate=0.02, max_depth=10, n_estimators=600;, score=-1.438 total time=  11.1s\n",
      "[CV 1/2; 49/72] START learning_rate=0.03, max_depth=5, n_estimators=300.........\n",
      "[CV 1/2; 49/72] END learning_rate=0.03, max_depth=5, n_estimators=300;, score=-1.404 total time=   2.4s\n",
      "[CV 2/2; 49/72] START learning_rate=0.03, max_depth=5, n_estimators=300.........\n",
      "[CV 2/2; 49/72] END learning_rate=0.03, max_depth=5, n_estimators=300;, score=-1.415 total time=   2.2s\n",
      "[CV 1/2; 50/72] START learning_rate=0.03, max_depth=5, n_estimators=400.........\n",
      "[CV 1/2; 50/72] END learning_rate=0.03, max_depth=5, n_estimators=400;, score=-1.405 total time=   3.0s\n",
      "[CV 2/2; 50/72] START learning_rate=0.03, max_depth=5, n_estimators=400.........\n",
      "[CV 2/2; 50/72] END learning_rate=0.03, max_depth=5, n_estimators=400;, score=-1.414 total time=   3.2s\n",
      "[CV 1/2; 51/72] START learning_rate=0.03, max_depth=5, n_estimators=500.........\n",
      "[CV 1/2; 51/72] END learning_rate=0.03, max_depth=5, n_estimators=500;, score=-1.405 total time=   3.7s\n",
      "[CV 2/2; 51/72] START learning_rate=0.03, max_depth=5, n_estimators=500.........\n",
      "[CV 2/2; 51/72] END learning_rate=0.03, max_depth=5, n_estimators=500;, score=-1.414 total time=   3.9s\n",
      "[CV 1/2; 52/72] START learning_rate=0.03, max_depth=5, n_estimators=600.........\n",
      "[CV 1/2; 52/72] END learning_rate=0.03, max_depth=5, n_estimators=600;, score=-1.406 total time=   4.5s\n",
      "[CV 2/2; 52/72] START learning_rate=0.03, max_depth=5, n_estimators=600.........\n",
      "[CV 2/2; 52/72] END learning_rate=0.03, max_depth=5, n_estimators=600;, score=-1.415 total time=   4.6s\n",
      "[CV 1/2; 53/72] START learning_rate=0.03, max_depth=6, n_estimators=300.........\n",
      "[CV 1/2; 53/72] END learning_rate=0.03, max_depth=6, n_estimators=300;, score=-1.404 total time=   3.0s\n",
      "[CV 2/2; 53/72] START learning_rate=0.03, max_depth=6, n_estimators=300.........\n",
      "[CV 2/2; 53/72] END learning_rate=0.03, max_depth=6, n_estimators=300;, score=-1.413 total time=   3.0s\n",
      "[CV 1/2; 54/72] START learning_rate=0.03, max_depth=6, n_estimators=400.........\n",
      "[CV 1/2; 54/72] END learning_rate=0.03, max_depth=6, n_estimators=400;, score=-1.407 total time=   3.9s\n",
      "[CV 2/2; 54/72] START learning_rate=0.03, max_depth=6, n_estimators=400.........\n",
      "[CV 2/2; 54/72] END learning_rate=0.03, max_depth=6, n_estimators=400;, score=-1.413 total time=   4.0s\n",
      "[CV 1/2; 55/72] START learning_rate=0.03, max_depth=6, n_estimators=500.........\n",
      "[CV 1/2; 55/72] END learning_rate=0.03, max_depth=6, n_estimators=500;, score=-1.409 total time=   4.8s\n",
      "[CV 2/2; 55/72] START learning_rate=0.03, max_depth=6, n_estimators=500.........\n",
      "[CV 2/2; 55/72] END learning_rate=0.03, max_depth=6, n_estimators=500;, score=-1.414 total time=   4.9s\n",
      "[CV 1/2; 56/72] START learning_rate=0.03, max_depth=6, n_estimators=600.........\n",
      "[CV 1/2; 56/72] END learning_rate=0.03, max_depth=6, n_estimators=600;, score=-1.411 total time=   5.7s\n",
      "[CV 2/2; 56/72] START learning_rate=0.03, max_depth=6, n_estimators=600.........\n",
      "[CV 2/2; 56/72] END learning_rate=0.03, max_depth=6, n_estimators=600;, score=-1.415 total time=   5.8s\n",
      "[CV 1/2; 57/72] START learning_rate=0.03, max_depth=7, n_estimators=300.........\n",
      "[CV 1/2; 57/72] END learning_rate=0.03, max_depth=7, n_estimators=300;, score=-1.408 total time=   3.6s\n",
      "[CV 2/2; 57/72] START learning_rate=0.03, max_depth=7, n_estimators=300.........\n",
      "[CV 2/2; 57/72] END learning_rate=0.03, max_depth=7, n_estimators=300;, score=-1.416 total time=   3.5s\n",
      "[CV 1/2; 58/72] START learning_rate=0.03, max_depth=7, n_estimators=400.........\n",
      "[CV 1/2; 58/72] END learning_rate=0.03, max_depth=7, n_estimators=400;, score=-1.412 total time=   4.7s\n",
      "[CV 2/2; 58/72] START learning_rate=0.03, max_depth=7, n_estimators=400.........\n",
      "[CV 2/2; 58/72] END learning_rate=0.03, max_depth=7, n_estimators=400;, score=-1.418 total time=   4.7s\n",
      "[CV 1/2; 59/72] START learning_rate=0.03, max_depth=7, n_estimators=500.........\n",
      "[CV 1/2; 59/72] END learning_rate=0.03, max_depth=7, n_estimators=500;, score=-1.414 total time=   5.8s\n",
      "[CV 2/2; 59/72] START learning_rate=0.03, max_depth=7, n_estimators=500.........\n",
      "[CV 2/2; 59/72] END learning_rate=0.03, max_depth=7, n_estimators=500;, score=-1.420 total time=   5.9s\n",
      "[CV 1/2; 60/72] START learning_rate=0.03, max_depth=7, n_estimators=600.........\n",
      "[CV 1/2; 60/72] END learning_rate=0.03, max_depth=7, n_estimators=600;, score=-1.417 total time=   6.4s\n",
      "[CV 2/2; 60/72] START learning_rate=0.03, max_depth=7, n_estimators=600.........\n",
      "[CV 2/2; 60/72] END learning_rate=0.03, max_depth=7, n_estimators=600;, score=-1.422 total time=   6.4s\n",
      "[CV 1/2; 61/72] START learning_rate=0.03, max_depth=8, n_estimators=300.........\n",
      "[CV 1/2; 61/72] END learning_rate=0.03, max_depth=8, n_estimators=300;, score=-1.415 total time=   4.2s\n",
      "[CV 2/2; 61/72] START learning_rate=0.03, max_depth=8, n_estimators=300.........\n",
      "[CV 2/2; 61/72] END learning_rate=0.03, max_depth=8, n_estimators=300;, score=-1.422 total time=   4.3s\n",
      "[CV 1/2; 62/72] START learning_rate=0.03, max_depth=8, n_estimators=400.........\n",
      "[CV 1/2; 62/72] END learning_rate=0.03, max_depth=8, n_estimators=400;, score=-1.418 total time=   5.7s\n",
      "[CV 2/2; 62/72] START learning_rate=0.03, max_depth=8, n_estimators=400.........\n",
      "[CV 2/2; 62/72] END learning_rate=0.03, max_depth=8, n_estimators=400;, score=-1.424 total time=   5.7s\n",
      "[CV 1/2; 63/72] START learning_rate=0.03, max_depth=8, n_estimators=500.........\n",
      "[CV 1/2; 63/72] END learning_rate=0.03, max_depth=8, n_estimators=500;, score=-1.422 total time=   6.7s\n",
      "[CV 2/2; 63/72] START learning_rate=0.03, max_depth=8, n_estimators=500.........\n",
      "[CV 2/2; 63/72] END learning_rate=0.03, max_depth=8, n_estimators=500;, score=-1.427 total time=   6.8s\n",
      "[CV 1/2; 64/72] START learning_rate=0.03, max_depth=8, n_estimators=600.........\n",
      "[CV 1/2; 64/72] END learning_rate=0.03, max_depth=8, n_estimators=600;, score=-1.426 total time=   8.3s\n",
      "[CV 2/2; 64/72] START learning_rate=0.03, max_depth=8, n_estimators=600.........\n",
      "[CV 2/2; 64/72] END learning_rate=0.03, max_depth=8, n_estimators=600;, score=-1.431 total time=   7.9s\n",
      "[CV 1/2; 65/72] START learning_rate=0.03, max_depth=9, n_estimators=300.........\n",
      "[CV 1/2; 65/72] END learning_rate=0.03, max_depth=9, n_estimators=300;, score=-1.420 total time=   4.2s\n",
      "[CV 2/2; 65/72] START learning_rate=0.03, max_depth=9, n_estimators=300.........\n",
      "[CV 2/2; 65/72] END learning_rate=0.03, max_depth=9, n_estimators=300;, score=-1.429 total time=   4.7s\n",
      "[CV 1/2; 66/72] START learning_rate=0.03, max_depth=9, n_estimators=400.........\n",
      "[CV 1/2; 66/72] END learning_rate=0.03, max_depth=9, n_estimators=400;, score=-1.426 total time=   6.4s\n",
      "[CV 2/2; 66/72] START learning_rate=0.03, max_depth=9, n_estimators=400.........\n",
      "[CV 2/2; 66/72] END learning_rate=0.03, max_depth=9, n_estimators=400;, score=-1.434 total time=   6.5s\n",
      "[CV 1/2; 67/72] START learning_rate=0.03, max_depth=9, n_estimators=500.........\n",
      "[CV 1/2; 67/72] END learning_rate=0.03, max_depth=9, n_estimators=500;, score=-1.430 total time=   7.9s\n",
      "[CV 2/2; 67/72] START learning_rate=0.03, max_depth=9, n_estimators=500.........\n",
      "[CV 2/2; 67/72] END learning_rate=0.03, max_depth=9, n_estimators=500;, score=-1.437 total time=   8.1s\n",
      "[CV 1/2; 68/72] START learning_rate=0.03, max_depth=9, n_estimators=600.........\n",
      "[CV 1/2; 68/72] END learning_rate=0.03, max_depth=9, n_estimators=600;, score=-1.434 total time=   9.7s\n",
      "[CV 2/2; 68/72] START learning_rate=0.03, max_depth=9, n_estimators=600.........\n",
      "[CV 2/2; 68/72] END learning_rate=0.03, max_depth=9, n_estimators=600;, score=-1.440 total time=   9.5s\n",
      "[CV 1/2; 69/72] START learning_rate=0.03, max_depth=10, n_estimators=300........\n",
      "[CV 1/2; 69/72] END learning_rate=0.03, max_depth=10, n_estimators=300;, score=-1.431 total time=   5.6s\n",
      "[CV 2/2; 69/72] START learning_rate=0.03, max_depth=10, n_estimators=300........\n",
      "[CV 2/2; 69/72] END learning_rate=0.03, max_depth=10, n_estimators=300;, score=-1.435 total time=   5.7s\n",
      "[CV 1/2; 70/72] START learning_rate=0.03, max_depth=10, n_estimators=400........\n",
      "[CV 1/2; 70/72] END learning_rate=0.03, max_depth=10, n_estimators=400;, score=-1.438 total time=   7.2s\n",
      "[CV 2/2; 70/72] START learning_rate=0.03, max_depth=10, n_estimators=400........\n",
      "[CV 2/2; 70/72] END learning_rate=0.03, max_depth=10, n_estimators=400;, score=-1.439 total time=   7.1s\n",
      "[CV 1/2; 71/72] START learning_rate=0.03, max_depth=10, n_estimators=500........\n",
      "[CV 1/2; 71/72] END learning_rate=0.03, max_depth=10, n_estimators=500;, score=-1.442 total time=   8.9s\n",
      "[CV 2/2; 71/72] START learning_rate=0.03, max_depth=10, n_estimators=500........\n",
      "[CV 2/2; 71/72] END learning_rate=0.03, max_depth=10, n_estimators=500;, score=-1.443 total time=   9.3s\n",
      "[CV 1/2; 72/72] START learning_rate=0.03, max_depth=10, n_estimators=600........\n",
      "[CV 1/2; 72/72] END learning_rate=0.03, max_depth=10, n_estimators=600;, score=-1.446 total time=   9.9s\n",
      "[CV 2/2; 72/72] START learning_rate=0.03, max_depth=10, n_estimators=600........\n",
      "[CV 2/2; 72/72] END learning_rate=0.03, max_depth=10, n_estimators=600;, score=-1.446 total time=  12.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03],\n",
       "                         &#x27;max_depth&#x27;: [5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;n_estimators&#x27;: [300, 400, 500, 600]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=2,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.01, 0.02, 0.03],\n",
       "                         &#x27;max_depth&#x27;: [5, 6, 7, 8, 9, 10],\n",
       "                         &#x27;n_estimators&#x27;: [300, 400, 500, 600]},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;, verbose=10)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "             predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=2,\n",
       "             estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                    callbacks=None, colsample_bylevel=None,\n",
       "                                    colsample_bynode=None,\n",
       "                                    colsample_bytree=None,\n",
       "                                    early_stopping_rounds=None,\n",
       "                                    enable_categorical=False, eval_metric=None,\n",
       "                                    feature_types=None, gamma=None, gpu_id=None,\n",
       "                                    grow_policy=None, importance_type=None,\n",
       "                                    interaction_constraints=None,\n",
       "                                    learning_rate=None, m...\n",
       "                                    max_cat_to_onehot=None, max_delta_step=None,\n",
       "                                    max_depth=None, max_leaves=None,\n",
       "                                    min_child_weight=None, missing=nan,\n",
       "                                    monotone_constraints=None, n_estimators=100,\n",
       "                                    n_jobs=None, num_parallel_tree=None,\n",
       "                                    predictor=None, random_state=None, ...),\n",
       "             param_grid={'learning_rate': [0.01, 0.02, 0.03],\n",
       "                         'max_depth': [5, 6, 7, 8, 9, 10],\n",
       "                         'n_estimators': [300, 400, 500, 600]},\n",
       "             scoring='neg_mean_absolute_error', verbose=10)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = xg.XGBRegressor()\n",
    "\n",
    "parameters = {\n",
    "              # 'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "              # 'objective':['reg:squarederror'],\n",
    "                # 'eval_metric'='rmse',\n",
    "              'learning_rate': [.01, .02, .03],\n",
    "              'max_depth': [5, 6, 7, 8, 9, 10],\n",
    "              # 'min_child_weight': [2,3,4],\n",
    "              # 'silent': [1],\n",
    "              # 'subsample': [0.7, 0.8],\n",
    "              # 'colsample_bytree': [0.7],\n",
    "              'n_estimators': [300, 400, 500, 600]}\n",
    "\n",
    "xgb_model_gridsearchcv = GridSearchCV(xgb1,\n",
    "                        parameters,\n",
    "                        cv = 2,\n",
    "                        # n_jobs = -1,\n",
    "                        scoring='neg_mean_absolute_error',\n",
    "                        verbose=10\n",
    "                                     )\n",
    "\n",
    "xgb_model_gridsearchcv.fit(train[X], train[y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model_gridsearchcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params_xgb = {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.3839899\n",
      "MAPE: 0.129012792492191\n",
      "MSE: 4.428327\n",
      "RMSE: 2.1043591\n",
      "R2 Square 0.5654910452215556\n",
      "__________________________________\n",
      "====================================\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.3551793\n",
      "MAPE: 0.12509559734639394\n",
      "MSE: 4.2693768\n",
      "RMSE: 2.066247\n",
      "R2 Square 0.5753634753844339\n",
      "__________________________________\n"
     ]
    }
   ],
   "source": [
    "xgb_model_gridsearchcv = xg.XGBRegressor(**best_params_xgb).fit(train[X], train[y])\n",
    "\n",
    "test_pred = xgb_model_gridsearchcv.predict(test[X])\n",
    "train_pred = xgb_model_gridsearchcv.predict(train[X])\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(test[y], test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(train[y], train_pred)\n",
    "\n",
    "results_df_temp = pd.DataFrame(data=[[\"XGB-GSCV\", *evaluate(test[y], test_pred)]], \n",
    "                            columns=['Model', 'MAE', 'MAPE', 'MSE', 'RMSE', 'R2_Score'])\n",
    "results_df = results_df.append(results_df_temp, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>1.378179</td>\n",
       "      <td>0.131256</td>\n",
       "      <td>4.231293</td>\n",
       "      <td>2.057011</td>\n",
       "      <td>0.584824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGB-GSCV</td>\n",
       "      <td>1.383990</td>\n",
       "      <td>0.129013</td>\n",
       "      <td>4.428327</td>\n",
       "      <td>2.104359</td>\n",
       "      <td>0.565491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model       MAE      MAPE       MSE      RMSE  R2_Score\n",
       "0       XGB  1.378179  0.131256  4.231293  2.057011  0.584824\n",
       "1  XGB-GSCV  1.383990  0.129013  4.428327  2.104359  0.565491"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by='MAE', ascending = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LightGBM optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'objective': trial.suggest_categorical('objective', ['regression_l1']),\n",
    "        'metrics': trial.suggest_categorical('metrics', ['mae']),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 1000,1200,1400),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.03),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 64, 96),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.75, 0.85),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.3, 0.4),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 10)\n",
    "    }\n",
    "    \n",
    "    lgbm_optuna = lightgbm.LGBMRegressor(**param).fit(train[X], train[y])\n",
    "    y_pred = lgbm_optuna.predict(test[X])\n",
    "    return metrics.mean_absolute_error(test[y], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-03 20:02:48,090] A new study created in memory with name: regression\n",
      "[I 2023-06-03 20:03:13,037] Trial 0 finished with value: 1.3571277701309936 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.014758341859480922, 'num_leaves': 74, 'colsample_bytree': 0.8164919832077873, 'min_split_gain': 0.3278405337927693, 'max_depth': 10}. Best is trial 0 with value: 1.3571277701309936.\n",
      "[I 2023-06-03 20:03:35,958] Trial 1 finished with value: 1.3590352123541465 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.013610188645523985, 'num_leaves': 72, 'colsample_bytree': 0.843699873010578, 'min_split_gain': 0.3177480177468518, 'max_depth': 10}. Best is trial 0 with value: 1.3571277701309936.\n",
      "[I 2023-06-03 20:03:54,659] Trial 2 finished with value: 1.3557991817857058 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02938680422025377, 'num_leaves': 79, 'colsample_bytree': 0.8080993120253522, 'min_split_gain': 0.3898550227351878, 'max_depth': 10}. Best is trial 2 with value: 1.3557991817857058.\n",
      "[I 2023-06-03 20:04:18,900] Trial 3 finished with value: 1.3536357512900368 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.023723218242766977, 'num_leaves': 96, 'colsample_bytree': 0.7970128586785106, 'min_split_gain': 0.382342550281508, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:04:40,069] Trial 4 finished with value: 1.358789879130048 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.0102965461329803, 'num_leaves': 76, 'colsample_bytree': 0.7897194058444148, 'min_split_gain': 0.3679626294409275, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:05:05,825] Trial 5 finished with value: 1.357047620959163 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.012017766894443008, 'num_leaves': 96, 'colsample_bytree': 0.8123402985719976, 'min_split_gain': 0.30629178741697927, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:05:28,033] Trial 6 finished with value: 1.3578037687055178 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.011481313697785855, 'num_leaves': 82, 'colsample_bytree': 0.7674995098083978, 'min_split_gain': 0.3258348333024531, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:05:50,217] Trial 7 finished with value: 1.3558724737852816 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.025135236148721422, 'num_leaves': 67, 'colsample_bytree': 0.7632625150190486, 'min_split_gain': 0.3521395082312955, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:06:08,487] Trial 8 finished with value: 1.3609978413409818 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.011717501407846557, 'num_leaves': 65, 'colsample_bytree': 0.8136457202476928, 'min_split_gain': 0.3242377064853985, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:06:30,872] Trial 9 finished with value: 1.356245695170361 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02911279264450662, 'num_leaves': 82, 'colsample_bytree': 0.7860164791936608, 'min_split_gain': 0.34937026434088697, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:06:56,472] Trial 10 finished with value: 1.3549215526246465 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.020187960558725106, 'num_leaves': 96, 'colsample_bytree': 0.7520482096286744, 'min_split_gain': 0.39650121834937063, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:07:23,404] Trial 11 finished with value: 1.3558598855012671 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.020065094543465466, 'num_leaves': 96, 'colsample_bytree': 0.7529295881845743, 'min_split_gain': 0.39640557453806397, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:07:47,132] Trial 12 finished with value: 1.354661460223319 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02116966551674759, 'num_leaves': 90, 'colsample_bytree': 0.7754644376760165, 'min_split_gain': 0.39970004704778195, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:08:06,535] Trial 13 finished with value: 1.3555372114463025 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.0228753767254518, 'num_leaves': 89, 'colsample_bytree': 0.7840313282765605, 'min_split_gain': 0.3824343434195542, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:08:27,815] Trial 14 finished with value: 1.3567161618855719 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.017264040622191182, 'num_leaves': 89, 'colsample_bytree': 0.7761125169205987, 'min_split_gain': 0.3804760237549444, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:08:52,208] Trial 15 finished with value: 1.3554185827222134 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02299257589234623, 'num_leaves': 89, 'colsample_bytree': 0.8021277340036962, 'min_split_gain': 0.37404718869420467, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:09:18,021] Trial 16 finished with value: 1.3575396177226575 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.017441058665120964, 'num_leaves': 91, 'colsample_bytree': 0.7889736521674712, 'min_split_gain': 0.39900388979901485, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:09:37,145] Trial 17 finished with value: 1.3556199363964414 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.025762822230815642, 'num_leaves': 92, 'colsample_bytree': 0.795929625675605, 'min_split_gain': 0.38608548948741817, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:09:58,983] Trial 18 finished with value: 1.35367839405754 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.022144622624623675, 'num_leaves': 86, 'colsample_bytree': 0.7780706636461533, 'min_split_gain': 0.3662011386428844, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:10:18,733] Trial 19 finished with value: 1.3560175119325535 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.01797415683297095, 'num_leaves': 85, 'colsample_bytree': 0.7976273912221459, 'min_split_gain': 0.37024416408539484, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:10:40,232] Trial 20 finished with value: 1.3551451511604944 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.026231467231689932, 'num_leaves': 84, 'colsample_bytree': 0.8262299187890784, 'min_split_gain': 0.359888198794587, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:11:00,035] Trial 21 finished with value: 1.3539710815305779 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02219223230124644, 'num_leaves': 93, 'colsample_bytree': 0.7770790515467741, 'min_split_gain': 0.3875269537915348, 'max_depth': 10}. Best is trial 3 with value: 1.3536357512900368.\n",
      "[I 2023-06-03 20:11:23,675] Trial 22 finished with value: 1.3533475821314818 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.022376530794128484, 'num_leaves': 92, 'colsample_bytree': 0.777672544426867, 'min_split_gain': 0.3800584544123259, 'max_depth': 10}. Best is trial 22 with value: 1.3533475821314818.\n",
      "[I 2023-06-03 20:11:47,222] Trial 23 finished with value: 1.3531485241509682 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.0238465224775758, 'num_leaves': 86, 'colsample_bytree': 0.7677037213450317, 'min_split_gain': 0.37891101491189083, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:12:08,546] Trial 24 finished with value: 1.355185167152226 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.024221537289322376, 'num_leaves': 93, 'colsample_bytree': 0.7658286545829699, 'min_split_gain': 0.3773412118164225, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:12:28,226] Trial 25 finished with value: 1.3555610687988013 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02691609530855038, 'num_leaves': 87, 'colsample_bytree': 0.7943180641314458, 'min_split_gain': 0.37584452292072884, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:12:50,161] Trial 26 finished with value: 1.3549956205878289 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.024169579685822087, 'num_leaves': 94, 'colsample_bytree': 0.7594507673078796, 'min_split_gain': 0.3878862788401367, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:13:09,194] Trial 27 finished with value: 1.3545206576324451 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.0240228411730431, 'num_leaves': 87, 'colsample_bytree': 0.7724604809046445, 'min_split_gain': 0.380205794044041, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:13:31,907] Trial 28 finished with value: 1.3552690368043505 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.021418251819117124, 'num_leaves': 79, 'colsample_bytree': 0.7824643135206015, 'min_split_gain': 0.36342368945229653, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:13:52,793] Trial 29 finished with value: 1.3554488760492809 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02736301085927076, 'num_leaves': 94, 'colsample_bytree': 0.7594483135122571, 'min_split_gain': 0.35548239857383906, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:14:14,113] Trial 30 finished with value: 1.3556373434614735 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.018996333359721448, 'num_leaves': 82, 'colsample_bytree': 0.7687665833339192, 'min_split_gain': 0.37244396694855214, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:14:34,677] Trial 31 finished with value: 1.3546554025880408 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.022359567104909543, 'num_leaves': 86, 'colsample_bytree': 0.7820258513774867, 'min_split_gain': 0.367183464845967, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:14:58,033] Trial 32 finished with value: 1.3565663299052122 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02378534585704157, 'num_leaves': 91, 'colsample_bytree': 0.7725318634376912, 'min_split_gain': 0.3466502528745145, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:15:17,110] Trial 33 finished with value: 1.354449011106838 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.021374101928896053, 'num_leaves': 75, 'colsample_bytree': 0.7776309734629131, 'min_split_gain': 0.36350713905544335, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:15:35,967] Trial 34 finished with value: 1.356919897397499 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.025008720116981173, 'num_leaves': 77, 'colsample_bytree': 0.7810054902489311, 'min_split_gain': 0.3835278420370999, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:15:57,958] Trial 35 finished with value: 1.3549416607513598 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.023110037616360123, 'num_leaves': 84, 'colsample_bytree': 0.7898176702299613, 'min_split_gain': 0.39313174763775516, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:16:22,190] Trial 36 finished with value: 1.3548817435026352 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02185615902749519, 'num_leaves': 88, 'colsample_bytree': 0.8049011754740658, 'min_split_gain': 0.390949527174602, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:16:40,521] Trial 37 finished with value: 1.3552117609196535 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02075607197120358, 'num_leaves': 73, 'colsample_bytree': 0.791776557306986, 'min_split_gain': 0.3763576079578012, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:17:04,932] Trial 38 finished with value: 1.3545966102897375 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.024872281647415014, 'num_leaves': 96, 'colsample_bytree': 0.7693751237721408, 'min_split_gain': 0.3677475215815891, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:17:24,778] Trial 39 finished with value: 1.3565705684414995 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.019429101449680727, 'num_leaves': 80, 'colsample_bytree': 0.7986868893617767, 'min_split_gain': 0.38364425891249376, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:17:49,263] Trial 40 finished with value: 1.353632084212371 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.023051422202933495, 'num_leaves': 94, 'colsample_bytree': 0.7873082929986512, 'min_split_gain': 0.3714009277255509, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:18:18,075] Trial 41 finished with value: 1.3548821191120897 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.023206616969679635, 'num_leaves': 94, 'colsample_bytree': 0.7874216504743606, 'min_split_gain': 0.3718344087586695, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:18:44,201] Trial 42 finished with value: 1.3550598725306402 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02231124505535694, 'num_leaves': 92, 'colsample_bytree': 0.7924427105865554, 'min_split_gain': 0.3785142220823859, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:19:14,086] Trial 43 finished with value: 1.3553099262317676 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.0207815737992515, 'num_leaves': 95, 'colsample_bytree': 0.7852178808642868, 'min_split_gain': 0.39149395361460027, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:19:35,219] Trial 44 finished with value: 1.3568944708950772 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02355872438377954, 'num_leaves': 71, 'colsample_bytree': 0.7802227013490818, 'min_split_gain': 0.3726272610376203, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:19:55,492] Trial 45 finished with value: 1.3556409736817865 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02476316975720313, 'num_leaves': 91, 'colsample_bytree': 0.7729033571657794, 'min_split_gain': 0.3841579844306288, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:20:14,475] Trial 46 finished with value: 1.3559822103118155 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.022274754961842398, 'num_leaves': 83, 'colsample_bytree': 0.7867956388024572, 'min_split_gain': 0.379409975108634, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:20:33,278] Trial 47 finished with value: 1.3548648194022814 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.025681738507436984, 'num_leaves': 90, 'colsample_bytree': 0.7631863506112484, 'min_split_gain': 0.37530805435522796, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:20:56,283] Trial 48 finished with value: 1.3540170124837274 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02302858030518912, 'num_leaves': 95, 'colsample_bytree': 0.7790179933507643, 'min_split_gain': 0.3683732307959271, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n",
      "[I 2023-06-03 20:21:16,055] Trial 49 finished with value: 1.3552058835112024 and parameters: {'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.02033036980687318, 'num_leaves': 88, 'colsample_bytree': 0.8037903641484861, 'min_split_gain': 0.3866826721601545, 'max_depth': 10}. Best is trial 23 with value: 1.3531485241509682.\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction='minimize', study_name='regression')\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: \n",
      "{'objective': 'regression_l1', 'metrics': 'mae', 'n_estimators': 1000, 'learning_rate': 0.0238465224775758, 'num_leaves': 86, 'colsample_bytree': 0.7677037213450317, 'min_split_gain': 0.37891101491189083, 'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "print('Best parameters: \\n{}'.format(study.best_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.3531485241509682\n",
      "MAPE: 0.12753429042784425\n",
      "MSE: 4.287570982557014\n",
      "RMSE: 2.0706450643596583\n",
      "R2 Square 0.5793020800121848\n",
      "__________________________________\n",
      "====================================\n",
      "Train set evaluation:\n",
      "_____________________________________\n",
      "MAE: 1.2396688729281162\n",
      "MAPE: 0.11555440762310211\n",
      "MSE: 3.8756186433560766\n",
      "RMSE: 1.968659097801363\n",
      "R2 Square 0.614527064674182\n",
      "__________________________________\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>1.371840</td>\n",
       "      <td>0.130086</td>\n",
       "      <td>4.227012</td>\n",
       "      <td>2.055970</td>\n",
       "      <td>0.585244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>1.354313</td>\n",
       "      <td>0.127634</td>\n",
       "      <td>4.285928</td>\n",
       "      <td>2.070248</td>\n",
       "      <td>0.579463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lgbm-optuna</td>\n",
       "      <td>1.353149</td>\n",
       "      <td>0.127534</td>\n",
       "      <td>4.287571</td>\n",
       "      <td>2.070645</td>\n",
       "      <td>0.579302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model       MAE      MAPE       MSE      RMSE  R2_Score\n",
       "0          XGB  1.371840  0.130086  4.227012  2.055970  0.585244\n",
       "1     LightGBM  1.354313  0.127634  4.285928  2.070248  0.579463\n",
       "2  lgbm-optuna  1.353149  0.127534  4.287571  2.070645  0.579302"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_optuna = lightgbm.LGBMRegressor(**study.best_params).fit(train[X],train[y])\n",
    "\n",
    "test_pred = lgbm_optuna.predict(test[X])\n",
    "train_pred = lgbm_optuna.predict(train[X])\n",
    "\n",
    "print('Test set evaluation:\\n_____________________________________')\n",
    "print_evaluate(test[y], test_pred)\n",
    "print('====================================')\n",
    "print('Train set evaluation:\\n_____________________________________')\n",
    "print_evaluate(train[y], train_pred)\n",
    "\n",
    "results_df_temp = pd.DataFrame(data=[[\"lgbm-optuna\", *evaluate(test[y], test_pred)]], \n",
    "                            columns=['Model', 'MAE', 'MAPE', 'MSE', 'RMSE', 'R2_Score'])\n",
    "results_df = results_df.append(results_df_temp, ignore_index=True)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "result_for_submission = lgbm_optuna.predict(test_df)\n",
    "submission['Age'] = result_for_submission\n",
    "submission['Age'] = submission['Age'].round()\n",
    "\n",
    "submission.to_csv('submission_result_lgbm_optuna.csv', index=False)\n",
    "# import os\n",
    "# os.chdir(r'../working')\n",
    "# from IPython.display import FileLink\n",
    "# FileLink(r'submission_result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>74051</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74052</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>74053</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74054</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74055</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49363</th>\n",
       "      <td>123414</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49364</th>\n",
       "      <td>123415</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49365</th>\n",
       "      <td>123416</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49366</th>\n",
       "      <td>123417</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49367</th>\n",
       "      <td>123418</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49368 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id   Age\n",
       "0       74051   7.0\n",
       "1       74052   8.0\n",
       "2       74053  10.0\n",
       "3       74054   9.0\n",
       "4       74055   7.0\n",
       "...       ...   ...\n",
       "49363  123414   9.0\n",
       "49364  123415   8.0\n",
       "49365  123416  13.0\n",
       "49366  123417   9.0\n",
       "49367  123418  12.0\n",
       "\n",
       "[49368 rows x 2 columns]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_df = pd.read_csv('submission_result_lgbm_optuna.csv')\n",
    "check_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
